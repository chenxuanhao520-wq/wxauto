# 📊 首轮聊天大模型接入评估

## 🎯 评估结论

**抛开成本，首轮聊天判断是否需要接入大模型？**

**答案**: ✅ **需要，但要智能分流！**

---

## 🔍 详细分析

### 场景1: 简单问候（20%）- ❌ 不需要大模型

**示例**：
- "你好"
- "在吗？"
- "谢谢"

**处理方式**：
```python
# 规则引擎处理（0成本，0延迟）
simple_greetings = {
    '你好': '您好！我是AI客服助手，很高兴为您服务！有什么可以帮您的吗？',
    '在吗': '在的！请问有什么可以帮您？',
    '谢谢': '不客气！还有其他需要帮助的吗？'
}

if content in simple_greetings:
    return simple_greetings[content]  # 直接返回，无需大模型
```

**效果**: 20%请求不调用大模型，节省20%成本

---

### 场景2: 知识库明确问题（50%）- ⚠️ 可选大模型

**示例**：
- "充电桩多少钱？"
- "支持哪些车型？"
- "保修多久？"

**判断逻辑**：
```python
# 1. 知识库检索
evidences = rag.retrieve(question)
confidence = rag.calculate_confidence(evidences)

if confidence >= 0.90:  # 高置信度
    # 知识库答案足够明确，可以直接返回（模板组装）
    answer = template_engine.format(evidences)
    # 不调用大模型，节省成本
    return answer

elif confidence >= 0.75:  # 中等置信度
    # 调用便宜的大模型（qwen-turbo）组织答案
    answer = await llm.generate(
        question=question,
        knowledge=evidences,
        model='qwen-turbo'
    )
    return answer

else:  # 低置信度
    # 调用强模型（deepseek）理解和推理
    answer = await llm.generate(
        question=question,
        knowledge=evidences,
        model='deepseek'
    )
    return answer
```

**效果**: 
- 高置信度（20%）: 不调用大模型
- 中置信度（50%）: 调用qwen-turbo
- 低置信度（30%）: 调用deepseek

**总节省**: 30%（20%不调用 + 10%用便宜模型）

---

### 场景3: 复杂问题（25%）- ✅ 必需大模型

**示例**：
- "我的充电桩红灯亮且有异响，怎么办？"
- "对比7kW和120kW哪个更适合我？"
- "如何选择适合的充电桩？"

**处理方式**：
```python
# 复杂问题必须用大模型
# 知识库只是提供参考，需要LLM理解、推理、综合

answer = await llm.generate(
    question=complex_question,
    knowledge=evidences,
    model='deepseek'  # 用强模型保证质量
)
```

**效果**: 25%请求用强模型，保证质量

---

### 场景4: 业务查询（5%）- ❌ 不需要大模型

**示例**：
- "查询订单123456"
- "我的物流信息"

**处理方式**：
```python
# 直接查ERP系统
order_info = erp_client.query_order(order_no)

# 模板组装结果
answer = f"您的订单{order_no}状态为：{order_info['status']}"

# 无需大模型
```

**效果**: 5%请求不调用大模型

---

## 🎯 智能判断策略

### 判断流程

```
首轮消息到达
    ↓
┌─────────────────────────────────┐
│ 步骤1: 快速规则判断              │
├─────────────────────────────────┤
│ • 简单问候？ → 规则引擎          │
│ • 业务查询？ → ERP系统           │
│ • 转人工请求？ → 直接转接        │
└────────────┬────────────────────┘
             ↓ 非简单规则
┌─────────────────────────────────┐
│ 步骤2: 知识库检索                │
├─────────────────────────────────┤
│ • 检索相关文档                   │
│ • 计算置信度                     │
└────────────┬────────────────────┘
             ↓
┌─────────────────────────────────┐
│ 步骤3: 置信度分流                │
├─────────────────────────────────┤
│ • 高置信度(≥0.90) → 模板组装    │
│ • 中置信度(0.75-0.90) → LLM轻量 │
│ • 低置信度(<0.75) → LLM强模型   │
└────────────┬────────────────────┘
             ↓
┌─────────────────────────────────┐
│ 步骤4: 智能路由选模型            │
├─────────────────────────────────┤
│ • 简单问题 → qwen-turbo         │
│ • 复杂问题 → deepseek            │
│ • 总结任务 → qwen-max            │
└─────────────────────────────────┘
```

---

## 💻 实现方案

### 首轮智能判断

```python
class FirstTurnRouter:
    """首轮对话智能路由器"""
    
    def __init__(self):
        # 简单规则库
        self.simple_rules = {
            '你好': '您好！我是AI客服助手...',
            '在吗': '在的！请问有什么可以帮您？',
            '谢谢': '不客气！还有其他需要帮助的吗？'
        }
        
        # 业务查询模式
        self.business_patterns = {
            'order': r'订单.*?(\d{6,})',
            'logistics': r'(物流|快递|发货)',
            'invoice': r'(发票|开票)'
        }
    
    async def should_use_llm(self, message: str, evidences: List = None) -> Dict:
        """
        判断是否需要调用大模型
        
        Returns:
            {
                'use_llm': bool,
                'reason': str,
                'suggested_model': str,
                'confidence': float
            }
        """
        # 1. 简单问候检查
        if message in self.simple_rules:
            return {
                'use_llm': False,
                'reason': '简单问候，规则引擎处理',
                'suggested_response': self.simple_rules[message],
                'confidence': 1.0
            }
        
        # 2. 超短消息检查
        if len(message) <= 3:
            return {
                'use_llm': False,
                'reason': '超短消息，规则引擎处理',
                'suggested_response': '您好！请问有什么可以帮您的吗？',
                'confidence': 0.9
            }
        
        # 3. 业务查询检查
        for pattern_type, pattern in self.business_patterns.items():
            import re
            match = re.search(pattern, message)
            if match:
                return {
                    'use_llm': False,
                    'reason': f'业务查询（{pattern_type}），ERP系统处理',
                    'suggested_action': 'query_erp',
                    'confidence': 0.95
                }
        
        # 4. 知识库置信度检查
        if evidences:
            from modules.rag.retriever import Retriever
            retriever = Retriever()
            confidence = retriever.calculate_confidence(evidences)
            
            if confidence >= 0.95:
                return {
                    'use_llm': False,
                    'reason': '知识库高置信度，模板组装',
                    'suggested_action': 'template_assembly',
                    'confidence': confidence
                }
            
            elif confidence >= 0.75:
                return {
                    'use_llm': True,
                    'reason': '知识库中等置信度，LLM组织答案',
                    'suggested_model': 'qwen-turbo',  # 便宜模型
                    'confidence': confidence
                }
            
            else:
                return {
                    'use_llm': True,
                    'reason': '知识库低置信度，LLM深度理解',
                    'suggested_model': 'deepseek',  # 强模型
                    'confidence': confidence
                }
        
        # 5. 默认：需要大模型
        return {
            'use_llm': True,
            'reason': '复杂问题，需要LLM理解',
            'suggested_model': 'qwen-plus',
            'confidence': 0.5
        }
```

---

## 📊 成本效果

### 对比分析（1000次首轮对话/天）

#### 方案A: 所有请求都调用大模型

```
场景分布:
  - 简单问候（200次）→ qwen-turbo: ¥0.24/天
  - 知识库明确（500次）→ qwen-turbo: ¥0.60/天
  - 复杂问题（250次）→ deepseek: ¥0.65/天
  - 业务查询（50次）→ qwen-turbo: ¥0.06/天

总成本: ¥1.55/天 = ¥46.5/月
```

#### 方案B: 智能判断（推荐）

```
场景分布:
  - 简单问候（200次）→ 规则引擎: ¥0/天 ✅
  - 知识库高置信（100次）→ 模板组装: ¥0/天 ✅
  - 知识库中置信（400次）→ qwen-turbo: ¥0.48/天
  - 复杂问题（250次）→ deepseek: ¥0.65/天
  - 业务查询（50次）→ ERP系统: ¥0/天 ✅

总成本: ¥1.13/天 = ¥33.9/月

节省: 27%
```

---

## 🎯 最终推荐

### 首轮智能分流策略

```
首轮消息
    ↓
简单问候（20%）→ 规则引擎 → 0成本
    ↓
业务查询（5%）→ ERP系统 → 0成本
    ↓
知识库检索
    ↓
高置信度（10%）→ 模板组装 → 0成本
    ↓
中置信度（40%）→ qwen-turbo → 低成本
    ↓
低置信度（25%）→ deepseek → 高质量
```

**效果**：
- 35%请求不调用大模型
- 40%请求用便宜模型
- 25%请求用强模型
- **总成本节省27%**
- **用户体验不打折**

---

## ✅ 立即实施

1. 添加首轮智能判断
2. 启用session_history
3. 上传到GitHub

**开发时间**: 30分钟
