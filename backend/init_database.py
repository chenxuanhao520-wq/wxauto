#!/usr/bin/env python3
"""
Supabase æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
åˆ›å»ºå¿…è¦çš„è¡¨å’Œ pgvector æ‰©å±•
"""

import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
    try:
        from supabase import create_client, Client
        
        logger.info("ğŸ” å¼€å§‹åˆå§‹åŒ– Supabase æ•°æ®åº“...")
        
        # è·å–ç¯å¢ƒå˜é‡
        url = os.getenv("SUPABASE_URL")
        service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        
        if not url or not service_key:
            logger.error("âŒ ç¼ºå°‘ Supabase ç¯å¢ƒå˜é‡")
            return False
        
        # åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ service role key ä»¥è·å¾—æ›´å¤šæƒé™ï¼‰
        supabase: Client = create_client(url, service_key)
        
        logger.info("âœ… Supabase å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        
        # 1. å¯ç”¨ pgvector æ‰©å±•
        logger.info("ğŸ”§ å¯ç”¨ pgvector æ‰©å±•...")
        try:
            # æ³¨æ„ï¼šè¿™éœ€è¦åœ¨ Supabase Dashboard çš„ SQL Editor ä¸­æ‰‹åŠ¨æ‰§è¡Œ
            logger.info("ğŸ’¡ è¯·åœ¨ Supabase Dashboard çš„ SQL Editor ä¸­æ‰§è¡Œä»¥ä¸‹ SQL:")
            logger.info("   CREATE EXTENSION IF NOT EXISTS vector;")
            logger.info("   ç„¶åæŒ‰ Enter ç»§ç»­...")
            input()
        except Exception as e:
            logger.warning(f"âš ï¸ pgvector æ‰©å±•è®¾ç½®: {e}")
        
        # 2. åˆ›å»ºåŸºç¡€è¡¨
        tables_to_create = [
            {
                "name": "messages",
                "sql": """
                CREATE TABLE IF NOT EXISTS messages (
                    id SERIAL PRIMARY KEY,
                    session_id TEXT NOT NULL,
                    sender_id TEXT NOT NULL,
                    sender_name TEXT,
                    content TEXT NOT NULL,
                    message_type TEXT DEFAULT 'text',
                    timestamp TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    group_id TEXT,
                    group_name TEXT,
                    is_ai_response BOOLEAN DEFAULT FALSE,
                    confidence_score FLOAT,
                    metadata JSONB
                );
                """
            },
            {
                "name": "sessions",
                "sql": """
                CREATE TABLE IF NOT EXISTS sessions (
                    id TEXT PRIMARY KEY,
                    group_id TEXT NOT NULL,
                    group_name TEXT,
                    start_time TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    end_time TIMESTAMP WITH TIME ZONE,
                    status TEXT DEFAULT 'active',
                    total_messages INTEGER DEFAULT 0,
                    ai_messages INTEGER DEFAULT 0,
                    summary TEXT,
                    metadata JSONB
                );
                """
            },
            {
                "name": "knowledge_chunks",
                "sql": """
                CREATE TABLE IF NOT EXISTS knowledge_chunks (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    title TEXT,
                    source TEXT,
                    chunk_index INTEGER,
                    metadata JSONB,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                );
                """
            },
            {
                "name": "knowledge_vectors",
                "sql": """
                CREATE TABLE IF NOT EXISTS knowledge_vectors (
                    id TEXT PRIMARY KEY,
                    content TEXT NOT NULL,
                    embedding VECTOR(1536),
                    metadata JSONB,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
                );
                """
            }
        ]
        
        # åˆ›å»ºè¡¨
        for table_info in tables_to_create:
            logger.info(f"ğŸ”§ åˆ›å»ºè¡¨: {table_info['name']}")
            try:
                # æ³¨æ„ï¼šSupabase å®¢æˆ·ç«¯ä¸èƒ½ç›´æ¥æ‰§è¡Œ DDLï¼Œéœ€è¦åœ¨ Dashboard ä¸­æ‰§è¡Œ
                logger.info(f"ğŸ’¡ è¯·åœ¨ Supabase Dashboard çš„ SQL Editor ä¸­æ‰§è¡Œä»¥ä¸‹ SQL:")
                logger.info(f"   {table_info['sql'].strip()}")
                logger.info("   æ‰§è¡Œå®ŒæˆåæŒ‰ Enter ç»§ç»­...")
                input()
                logger.info(f"âœ… è¡¨ {table_info['name']} åˆ›å»ºå®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºè¡¨ {table_info['name']} å¤±è´¥: {e}")
        
        # 3. åˆ›å»ºç´¢å¼•
        indexes_to_create = [
            {
                "name": "messages_session_idx",
                "sql": "CREATE INDEX IF NOT EXISTS messages_session_idx ON messages(session_id);"
            },
            {
                "name": "messages_timestamp_idx", 
                "sql": "CREATE INDEX IF NOT EXISTS messages_timestamp_idx ON messages(timestamp);"
            },
            {
                "name": "sessions_group_idx",
                "sql": "CREATE INDEX IF NOT EXISTS sessions_group_idx ON sessions(group_id);"
            },
            {
                "name": "knowledge_vectors_embedding_idx",
                "sql": "CREATE INDEX IF NOT EXISTS knowledge_vectors_embedding_idx ON knowledge_vectors USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);"
            }
        ]
        
        for index_info in indexes_to_create:
            logger.info(f"ğŸ”§ åˆ›å»ºç´¢å¼•: {index_info['name']}")
            logger.info(f"ğŸ’¡ è¯·åœ¨ Supabase Dashboard çš„ SQL Editor ä¸­æ‰§è¡Œä»¥ä¸‹ SQL:")
            logger.info(f"   {index_info['sql']}")
            logger.info("   æ‰§è¡Œå®ŒæˆåæŒ‰ Enter ç»§ç»­...")
            input()
            logger.info(f"âœ… ç´¢å¼• {index_info['name']} åˆ›å»ºå®Œæˆ")
        
        # 4. åˆ›å»º RPC å‡½æ•°
        rpc_functions = [
            {
                "name": "search_embeddings",
                "sql": """
                CREATE OR REPLACE FUNCTION search_embeddings(
                    query_embedding VECTOR(1536),
                    match_count INTEGER DEFAULT 10,
                    filter JSONB DEFAULT '{}'::jsonb
                )
                RETURNS TABLE(
                    id TEXT,
                    content TEXT,
                    similarity FLOAT,
                    metadata JSONB
                )
                LANGUAGE plpgsql
                AS $$
                BEGIN
                    RETURN QUERY
                    SELECT 
                        kv.id,
                        kv.content,
                        1 - (kv.embedding <=> query_embedding) AS similarity,
                        kv.metadata
                    FROM knowledge_vectors kv
                    WHERE 
                        CASE 
                            WHEN filter = '{}'::jsonb THEN TRUE
                            ELSE kv.metadata @> filter
                        END
                    ORDER BY kv.embedding <=> query_embedding
                    LIMIT match_count;
                END;
                $$;
                """
            }
        ]
        
        for rpc_info in rpc_functions:
            logger.info(f"ğŸ”§ åˆ›å»º RPC å‡½æ•°: {rpc_info['name']}")
            logger.info(f"ğŸ’¡ è¯·åœ¨ Supabase Dashboard çš„ SQL Editor ä¸­æ‰§è¡Œä»¥ä¸‹ SQL:")
            logger.info(f"   {rpc_info['sql'].strip()}")
            logger.info("   æ‰§è¡Œå®ŒæˆåæŒ‰ Enter ç»§ç»­...")
            input()
            logger.info(f"âœ… RPC å‡½æ•° {rpc_info['name']} åˆ›å»ºå®Œæˆ")
        
        logger.info("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


async def test_after_init():
    """åˆå§‹åŒ–åæµ‹è¯•"""
    try:
        from supabase import create_client, Client
        
        logger.info("ğŸ” æµ‹è¯•åˆå§‹åŒ–åçš„æ•°æ®åº“...")
        
        url = os.getenv("SUPABASE_URL")
        key = os.getenv("SUPABASE_ANON_KEY")
        
        supabase: Client = create_client(url, key)
        
        # æµ‹è¯•å„ä¸ªè¡¨
        tables_to_test = ['messages', 'sessions', 'knowledge_chunks', 'knowledge_vectors']
        
        for table in tables_to_test:
            try:
                result = supabase.table(table).select('*').limit(1).execute()
                logger.info(f"âœ… è¡¨ {table} æµ‹è¯•æˆåŠŸ: {len(result.data)} æ¡è®°å½•")
            except Exception as e:
                logger.error(f"âŒ è¡¨ {table} æµ‹è¯•å¤±è´¥: {e}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–åæµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹ Supabase æ•°æ®åº“åˆå§‹åŒ–...")
    logger.info("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_vars = ['SUPABASE_URL', 'SUPABASE_SERVICE_ROLE_KEY']
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        logger.error(f"âŒ ç¼ºå°‘ç¯å¢ƒå˜é‡: {missing_vars}")
        return
    
    logger.info("âœ… ç¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    success = await init_database()
    
    if success:
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆï¼")
        logger.info("=" * 60)
        
        # æµ‹è¯•åˆå§‹åŒ–ç»“æœ
        logger.info("\nğŸ” æµ‹è¯•åˆå§‹åŒ–ç»“æœ...")
        await test_after_init()
        
    else:
        logger.error("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")


if __name__ == "__main__":
    asyncio.run(main())
