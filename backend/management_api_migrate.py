#!/usr/bin/env python3
"""
é€šè¿‡ Supabase Management API ä¿®æ”¹æ•°æ®åº“ç»“æ„
æ”¯æŒ GLM 1024 ç»´å‘é‡
"""

import os
import sys
import asyncio
import logging
import aiohttp
import json
from datetime import datetime
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SupabaseManagementMigrator:
    """Supabase Management API è¿ç§»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¿ç§»å™¨"""
        self.url = os.getenv("SUPABASE_URL")
        self.service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        
        if not self.url or not self.service_key:
            raise ValueError("ç¼ºå°‘ Supabase ç¯å¢ƒå˜é‡")
        
        logger.info("âœ… Supabase Management API è¿ç§»å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    async def execute_sql_via_rest(self, sql_query):
        """é€šè¿‡ REST API æ‰§è¡Œ SQL"""
        try:
            # å°è¯•é€šè¿‡ SQL Editor API
            headers = {
                "Authorization": f"Bearer {self.service_key}",
                "Content-Type": "application/json",
                "apikey": self.service_key
            }
            
            # å°è¯•ä¸åŒçš„ API ç«¯ç‚¹
            endpoints = [
                f"{self.url}/rest/v1/rpc/exec_sql",
                f"{self.url}/rest/v1/rpc/execute_sql",
                f"{self.url}/rest/v1/rpc/run_sql",
                f"{self.url}/sql/v1/query"
            ]
            
            for endpoint in endpoints:
                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.post(
                            endpoint,
                            headers=headers,
                            json={"sql": sql_query}
                        ) as response:
                            if response.status == 200:
                                result = await response.json()
                                logger.info(f"âœ… SQL æ‰§è¡ŒæˆåŠŸ: {endpoint}")
                                return True
                            else:
                                logger.debug(f"âš ï¸ ç«¯ç‚¹ {endpoint} å¤±è´¥: {response.status}")
                except Exception as e:
                    logger.debug(f"âš ï¸ ç«¯ç‚¹ {endpoint} å¼‚å¸¸: {e}")
                    continue
            
            logger.error("âŒ æ‰€æœ‰ SQL æ‰§è¡Œç«¯ç‚¹éƒ½å¤±è´¥")
            return False
            
        except Exception as e:
            logger.error(f"âŒ SQL æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    async def migrate_via_direct_api(self):
        """é€šè¿‡ç›´æ¥ API è°ƒç”¨è¿ç§»"""
        try:
            logger.info("ğŸ”§ é€šè¿‡ç›´æ¥ API è°ƒç”¨è¿ç§»æ•°æ®åº“...")
            
            # 1. åˆ é™¤ç°æœ‰è¡¨
            logger.info("ğŸ—‘ï¸ åˆ é™¤ç°æœ‰ embeddings è¡¨...")
            
            # å°è¯•ç›´æ¥åˆ é™¤è¡¨
            try:
                from supabase import create_client, Client
                supabase: Client = create_client(self.url, self.service_key)
                
                # å…ˆæ¸…ç©ºè¡¨
                result = supabase.table('embeddings').delete().neq('id', 0).execute()
                logger.info("âœ… ç°æœ‰æ•°æ®æ¸…ç©ºæˆåŠŸ")
                
                # å°è¯•åˆ é™¤è¡¨ç»“æ„ï¼ˆé€šè¿‡ REST APIï¼‰
                delete_sql = "DROP TABLE IF EXISTS embeddings CASCADE;"
                await self.execute_sql_via_rest(delete_sql)
                
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ é™¤è¡¨å¤±è´¥: {e}")
            
            # 2. åˆ›å»ºæ–°è¡¨
            logger.info("ğŸ”¨ åˆ›å»ºæ–°çš„ embeddings è¡¨ï¼ˆ1024 ç»´ï¼‰...")
            
            create_table_sql = """
            CREATE TABLE embeddings (
                id BIGINT PRIMARY KEY,
                content TEXT NOT NULL,
                embedding vector(1024) NOT NULL,
                metadata JSONB DEFAULT '{}'::jsonb,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
            """
            
            # å°è¯•é€šè¿‡ REST API åˆ›å»ºè¡¨
            table_created = await self.execute_sql_via_rest(create_table_sql)
            
            if not table_created:
                logger.warning("âš ï¸ é€šè¿‡ API åˆ›å»ºè¡¨å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•")
                # è¿™é‡Œå¯ä»¥æ·»åŠ å…¶ä»–åˆ›å»ºè¡¨çš„æ–¹æ³•
                return False
            
            # 3. åˆ›å»ºæœç´¢å‡½æ•°
            logger.info("ğŸ”¨ åˆ›å»º search_embeddings å‡½æ•°...")
            
            create_function_sql = """
            CREATE OR REPLACE FUNCTION search_embeddings(
                query_embedding vector(1024),
                match_count int DEFAULT 5,
                similarity_threshold float DEFAULT 0.7
            )
            RETURNS TABLE (
                id BIGINT,
                content TEXT,
                metadata JSONB,
                similarity FLOAT
            )
            LANGUAGE SQL STABLE
            AS $$
                SELECT 
                    embeddings.id,
                    embeddings.content,
                    embeddings.metadata,
                    1 - (embeddings.embedding <=> query_embedding) AS similarity
                FROM embeddings
                WHERE 1 - (embeddings.embedding <=> query_embedding) > similarity_threshold
                ORDER BY embeddings.embedding <=> query_embedding
                LIMIT match_count;
            $$;
            """
            
            function_created = await self.execute_sql_via_rest(create_function_sql)
            
            if function_created:
                logger.info("âœ… æ•°æ®åº“ç»“æ„è¿ç§»å®Œæˆï¼")
                return True
            else:
                logger.error("âŒ å‡½æ•°åˆ›å»ºå¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            return False
    
    async def create_glm_knowledge_base(self):
        """åˆ›å»º GLM çŸ¥è¯†åº“"""
        try:
            logger.info("ğŸ”§ åˆ›å»º GLM çŸ¥è¯†åº“...")
            
            # å¯¼å…¥ GLM åµŒå…¥æœåŠ¡
            from glm_embedding_service import GLMEmbeddingService
            
            embedding_service = GLMEmbeddingService()
            
            # çŸ¥è¯†åº“æ–‡æ¡£
            knowledge_docs = [
                {
                    "title": "å……ç”µæ¡©æ•…éšœæ’é™¤æŒ‡å—",
                    "content": "å……ç”µæ¡©æ•…éšœæ’é™¤æŒ‡å—ï¼š1.æ£€æŸ¥ç”µæºè¿æ¥æ˜¯å¦æ­£å¸¸ 2.ç¡®è®¤æŒ‡ç¤ºç¯çŠ¶æ€ 3.é‡å¯è®¾å¤‡ 4.æ£€æŸ¥é€šä¿¡è¿æ¥ 5.è”ç³»æŠ€æœ¯æ”¯æŒ",
                    "category": "troubleshooting"
                },
                {
                    "title": "å……ç”µæ¡©å®‰è£…æ­¥éª¤",
                    "content": "å……ç”µæ¡©å®‰è£…æ­¥éª¤ï¼š1.é€‰æ‹©åˆé€‚ä½ç½® 2.å®‰è£…å›ºå®šæ”¯æ¶ 3.è¿æ¥ç”µæºçº¿ 4.æµ‹è¯•åŠŸèƒ½ 5.è®°å½•å®‰è£…ä¿¡æ¯",
                    "category": "installation"
                },
                {
                    "title": "å……ç”µæ¡©ç»´æŠ¤ä¿å…»",
                    "content": "å……ç”µæ¡©ç»´æŠ¤ä¿å…»ï¼š1.å®šæœŸæ¸…æ´è®¾å¤‡ 2.æ£€æŸ¥è¿æ¥çŠ¶æ€ 3.æ›´æ–°è½¯ä»¶ç‰ˆæœ¬ 4.è®°å½•ç»´æŠ¤æ—¥å¿— 5.é¢„é˜²æ€§ç»´æŠ¤",
                    "category": "maintenance"
                },
                {
                    "title": "å……ç”µæ¡©å®‰å…¨æ“ä½œè§„ç¨‹",
                    "content": "å®‰å…¨æ“ä½œè§„ç¨‹ï¼š1.æ“ä½œå‰æ£€æŸ¥è®¾å¤‡çŠ¶æ€ 2.ä½©æˆ´é˜²æŠ¤ç”¨å“ 3.æŒ‰è§„ç¨‹æ“ä½œ 4.è®°å½•æ“ä½œæ—¥å¿— 5.åº”æ€¥å¤„ç†",
                    "category": "safety"
                },
                {
                    "title": "å……ç”µæ¡©æ•…éšœä»£ç è¯´æ˜",
                    "content": "æ•…éšœä»£ç ï¼šE001-ç”µæºæ•…éšœ E002-é€šä¿¡æ•…éšœ E003-æ¸©åº¦å¼‚å¸¸ E004-è¿‡æµä¿æŠ¤ E005-æ¥åœ°æ•…éšœ",
                    "category": "technical"
                }
            ]
            
            from supabase import create_client, Client
            supabase: Client = create_client(self.url, self.service_key)
            
            added_count = 0
            
            for i, doc_data in enumerate(knowledge_docs):
                try:
                    logger.info(f"ğŸ“ å¤„ç†æ–‡æ¡£ {i+1}/{len(knowledge_docs)}: {doc_data['title']}")
                    
                    # ç”Ÿæˆ GLM åµŒå…¥å‘é‡
                    embedding = await embedding_service.embed_text(doc_data["content"])
                    
                    if embedding:
                        # åˆ›å»ºæ–‡æ¡£è®°å½•
                        doc_id = int(datetime.now().timestamp()) + i
                        
                        document = {
                            "id": doc_id,
                            "content": doc_data["content"],
                            "embedding": embedding,
                            "metadata": {
                                "title": doc_data["title"],
                                "category": doc_data["category"],
                                "source": "glm_knowledge_base",
                                "created_at": datetime.now().isoformat()
                            }
                        }
                        
                        # æ’å…¥æ•°æ®åº“
                        result = supabase.table('embeddings').insert(document).execute()
                        
                        if result.data:
                            added_count += 1
                            logger.info(f"âœ… æ–‡æ¡£æ·»åŠ æˆåŠŸ: {doc_data['title']}")
                        else:
                            logger.warning(f"âš ï¸ æ–‡æ¡£æ·»åŠ å¤±è´¥: {doc_data['title']}")
                    else:
                        logger.warning(f"âš ï¸ åµŒå…¥ç”Ÿæˆå¤±è´¥: {doc_data['title']}")
                        
                except Exception as e:
                    logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {doc_data['title']}: {e}")
                    continue
            
            logger.info(f"âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆ: {added_count}/{len(knowledge_docs)} æ¡æ–‡æ¡£")
            return True
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ é€šè¿‡ Supabase Management API è¿ç§»æ•°æ®åº“...")
    logger.info("=" * 60)
    
    try:
        # åˆå§‹åŒ–è¿ç§»å™¨
        migrator = SupabaseManagementMigrator()
        
        # æ‰§è¡Œè¿ç§»
        logger.info("\nğŸ”§ æ‰§è¡Œæ•°æ®åº“è¿ç§»...")
        migrate_ok = await migrator.migrate_via_direct_api()
        
        if migrate_ok:
            # åˆ›å»ºçŸ¥è¯†åº“
            logger.info("\nğŸ”§ åˆ›å»º GLM çŸ¥è¯†åº“...")
            kb_ok = await migrator.create_glm_knowledge_base()
            
            # è¾“å‡ºæ€»ç»“
            logger.info("\n" + "=" * 60)
            logger.info("ğŸ“Š æ•°æ®åº“è¿ç§»ç»“æœ:")
            logger.info("=" * 60)
            
            logger.info(f"æ•°æ®åº“è¿ç§»: {'âœ… æˆåŠŸ' if migrate_ok else 'âŒ å¤±è´¥'}")
            logger.info(f"çŸ¥è¯†åº“æ„å»º: {'âœ… æˆåŠŸ' if kb_ok else 'âŒ å¤±è´¥'}")
            
            if migrate_ok and kb_ok:
                logger.info("\nğŸ‰ GLM åµŒå…¥æœåŠ¡å‡çº§å…¨éƒ¨å®Œæˆï¼")
                logger.info("ğŸ’¡ ä½¿ç”¨æ™ºè°± GLM embedding-2 æ¨¡å‹")
                logger.info("ğŸ’¡ å‘é‡ç»´åº¦: 1024")
                logger.info("ğŸ’¡ çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
            else:
                logger.info("\nâš ï¸ éƒ¨åˆ†å‡çº§æœªå®Œæˆ")
        else:
            logger.error("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥")
        
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
