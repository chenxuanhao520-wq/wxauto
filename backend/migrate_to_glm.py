#!/usr/bin/env python3
"""
æ•°æ®åº“è¿ç§»è„šæœ¬ - æ”¯æŒ GLM 1024 ç»´å‘é‡
"""

import os
import sys
import asyncio
import logging
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseMigrator:
    """æ•°æ®åº“è¿ç§»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¿ç§»å™¨"""
        self.url = os.getenv("SUPABASE_URL")
        self.service_key = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
        
        if not self.url or not self.service_key:
            raise ValueError("ç¼ºå°‘ Supabase ç¯å¢ƒå˜é‡")
        
        from supabase import create_client, Client
        self.supabase: Client = create_client(self.url, self.service_key)
        
        logger.info("âœ… æ•°æ®åº“è¿ç§»å™¨åˆå§‹åŒ–æˆåŠŸ")
    
    async def migrate_to_glm_dimensions(self):
        """è¿ç§»åˆ° GLM 1024 ç»´å‘é‡"""
        try:
            logger.info("ğŸ”§ å¼€å§‹æ•°æ®åº“è¿ç§» - æ”¯æŒ GLM 1024 ç»´å‘é‡...")
            
            # 1. åˆ é™¤ç°æœ‰çš„ embeddings è¡¨
            logger.info("ğŸ—‘ï¸ åˆ é™¤ç°æœ‰ embeddings è¡¨...")
            try:
                drop_result = self.supabase.rpc('exec_sql', {
                    'sql': 'DROP TABLE IF EXISTS embeddings CASCADE;'
                }).execute()
                logger.info("âœ… ç°æœ‰è¡¨åˆ é™¤æˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ é™¤è¡¨å¤±è´¥ï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰: {e}")
            
            # 2. åˆ›å»ºæ–°çš„ embeddings è¡¨ï¼ˆ1024 ç»´ï¼‰
            logger.info("ğŸ”¨ åˆ›å»ºæ–°çš„ embeddings è¡¨ï¼ˆ1024 ç»´ï¼‰...")
            
            create_table_sql = """
            CREATE TABLE embeddings (
                id BIGINT PRIMARY KEY,
                content TEXT NOT NULL,
                embedding vector(1024) NOT NULL,
                metadata JSONB DEFAULT '{}'::jsonb,
                created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
                updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
            );
            """
            
            try:
                create_result = self.supabase.rpc('exec_sql', {
                    'sql': create_table_sql
                }).execute()
                logger.info("âœ… æ–°è¡¨åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
                return False
            
            # 3. åˆ›å»ºå‘é‡ç´¢å¼•
            logger.info("ğŸ”¨ åˆ›å»ºå‘é‡ç´¢å¼•...")
            
            create_index_sql = """
            CREATE INDEX ON embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
            """
            
            try:
                index_result = self.supabase.rpc('exec_sql', {
                    'sql': create_index_sql
                }).execute()
                logger.info("âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸ åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
            
            # 4. æ›´æ–° search_embeddings å‡½æ•°
            logger.info("ğŸ”¨ æ›´æ–° search_embeddings å‡½æ•°...")
            
            create_function_sql = """
            CREATE OR REPLACE FUNCTION search_embeddings(
                query_embedding vector(1024),
                match_count int DEFAULT 5,
                similarity_threshold float DEFAULT 0.7
            )
            RETURNS TABLE (
                id BIGINT,
                content TEXT,
                metadata JSONB,
                similarity FLOAT
            )
            LANGUAGE SQL STABLE
            AS $$
                SELECT 
                    embeddings.id,
                    embeddings.content,
                    embeddings.metadata,
                    1 - (embeddings.embedding <=> query_embedding) AS similarity
                FROM embeddings
                WHERE 1 - (embeddings.embedding <=> query_embedding) > similarity_threshold
                ORDER BY embeddings.embedding <=> query_embedding
                LIMIT match_count;
            $$;
            """
            
            try:
                function_result = self.supabase.rpc('exec_sql', {
                    'sql': create_function_sql
                }).execute()
                logger.info("âœ… search_embeddings å‡½æ•°æ›´æ–°æˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ æ›´æ–°å‡½æ•°å¤±è´¥: {e}")
                return False
            
            logger.info("âœ… æ•°æ®åº“è¿ç§»å®Œæˆï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            return False
    
    async def verify_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        try:
            logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
            
            # æ£€æŸ¥è¡¨ç»“æ„
            logger.info("ğŸ“‹ æ£€æŸ¥è¡¨ç»“æ„...")
            try:
                result = self.supabase.table('embeddings').select('*').limit(1).execute()
                logger.info("âœ… embeddings è¡¨å­˜åœ¨")
            except Exception as e:
                logger.error(f"âŒ embeddings è¡¨ä¸å­˜åœ¨: {e}")
                return False
            
            # æ£€æŸ¥å‡½æ•°
            logger.info("ğŸ“‹ æ£€æŸ¥ search_embeddings å‡½æ•°...")
            try:
                # ä½¿ç”¨æµ‹è¯•å‘é‡è°ƒç”¨å‡½æ•°
                test_vector = [0.1] * 1024
                result = self.supabase.rpc('search_embeddings', {
                    'query_embedding': test_vector,
                    'match_count': 1
                }).execute()
                logger.info("âœ… search_embeddings å‡½æ•°æ­£å¸¸")
            except Exception as e:
                logger.error(f"âŒ search_embeddings å‡½æ•°å¼‚å¸¸: {e}")
                return False
            
            logger.info("âœ… è¿ç§»éªŒè¯æˆåŠŸï¼")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿ç§»éªŒè¯å¤±è´¥: {e}")
            return False

async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ æ•°æ®åº“è¿ç§» - æ”¯æŒ GLM 1024 ç»´å‘é‡...")
    logger.info("=" * 60)
    
    try:
        # åˆå§‹åŒ–è¿ç§»å™¨
        migrator = DatabaseMigrator()
        
        # æ‰§è¡Œè¿ç§»
        logger.info("\nğŸ”§ æ‰§è¡Œæ•°æ®åº“è¿ç§»...")
        migrate_ok = await migrator.migrate_to_glm_dimensions()
        
        if not migrate_ok:
            logger.error("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥")
            return
        
        # éªŒè¯è¿ç§»
        logger.info("\nğŸ” éªŒè¯è¿ç§»ç»“æœ...")
        verify_ok = await migrator.verify_migration()
        
        # è¾“å‡ºæ€»ç»“
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“Š æ•°æ®åº“è¿ç§»ç»“æœ:")
        logger.info("=" * 60)
        
        logger.info(f"æ•°æ®åº“è¿ç§»: {'âœ… æˆåŠŸ' if migrate_ok else 'âŒ å¤±è´¥'}")
        logger.info(f"è¿ç§»éªŒè¯: {'âœ… æˆåŠŸ' if verify_ok else 'âŒ å¤±è´¥'}")
        
        # æ€»ä½“è¯„ä¼°
        all_ok = migrate_ok and verify_ok
        
        if all_ok:
            logger.info("\nğŸ‰ æ•°æ®åº“è¿ç§»å…¨éƒ¨å®Œæˆï¼")
            logger.info("ğŸ’¡ ç°åœ¨æ”¯æŒ GLM 1024 ç»´å‘é‡")
            logger.info("ğŸ’¡ å¯ä»¥æ­£å¸¸ä½¿ç”¨ GLM åµŒå…¥æœåŠ¡")
            logger.info("ğŸ’¡ å‘é‡æœç´¢åŠŸèƒ½å·²å°±ç»ª")
        else:
            logger.info("\nâš ï¸ è¿ç§»æœªå®Œå…¨æˆåŠŸ")
            logger.info("ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®åº“æƒé™å’Œç½‘ç»œè¿æ¥")
        
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(main())
