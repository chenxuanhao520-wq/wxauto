"""
è´¨é‡æ§åˆ¶å™¨ - æè‡´è´¨é‡ä¿è¯
è´Ÿè´£ä¸¥æ ¼çš„è´¨é‡æ§åˆ¶ã€é—®é¢˜æ£€æµ‹ã€åé¦ˆç”Ÿæˆå’Œæ™ºèƒ½ä¿®å¤
"""
import logging
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import json

logger = logging.getLogger(__name__)


@dataclass
class QualityIssue:
    """è´¨é‡é—®é¢˜"""
    issue_id: str
    issue_type: str  # missing_info, duplicate, low_quality, format_error, incomplete
    severity: str  # critical, high, medium, low
    description: str
    affected_chunks: List[str]
    auto_fixable: bool
    fix_suggestion: str
    detected_at: datetime = field(default_factory=datetime.now)


@dataclass
class QualityFeedback:
    """è´¨é‡åé¦ˆæŠ¥å‘Š"""
    document_id: str
    overall_score: float
    passed: bool
    issues: List[QualityIssue]
    warnings: List[str]
    fix_suggestions: List[str]
    auto_fix_available: bool
    manual_review_required: bool
    feedback_message: str


@dataclass
class AutoFixResult:
    """è‡ªåŠ¨ä¿®å¤ç»“æœ"""
    success: bool
    original_content: str
    fixed_content: str
    fix_method: str  # rule_based, llm_assisted, hybrid
    confidence: float
    changes_made: List[str]
    requires_human_review: bool


class QualityController:
    """
    è´¨é‡æ§åˆ¶å™¨
    
    åŠŸèƒ½ï¼š
    1. ä¸¥æ ¼è´¨é‡æ£€æµ‹
    2. æ™ºèƒ½é—®é¢˜è¯†åˆ«
    3. ç”Ÿæˆè¯¦ç»†åé¦ˆ
    4. å¤§æ¨¡å‹è¾…åŠ©ä¿®å¤
    5. åŠ¨æ€è´¨é‡æ ‡å‡†
    """
    
    def __init__(
        self,
        threshold: float = 0.75,
        strict_mode: bool = True,
        enable_auto_fix: bool = True,
        enable_llm_fix: bool = True,
        ai_gateway=None
    ):
        """
        åˆå§‹åŒ–è´¨é‡æ§åˆ¶å™¨
        
        Args:
            threshold: è´¨é‡é˜ˆå€¼
            strict_mode: ä¸¥æ ¼æ¨¡å¼ï¼ˆæ›´ä¸¥æ ¼çš„æ£€æŸ¥ï¼‰
            enable_auto_fix: æ˜¯å¦å¯ç”¨è‡ªåŠ¨ä¿®å¤
            enable_llm_fix: æ˜¯å¦å¯ç”¨å¤§æ¨¡å‹ä¿®å¤
            ai_gateway: AIç½‘å…³ï¼ˆç”¨äºå¤§æ¨¡å‹ä¿®å¤ï¼‰
        """
        self.threshold = threshold
        self.strict_mode = strict_mode
        self.enable_auto_fix = enable_auto_fix
        self.enable_llm_fix = enable_llm_fix
        self.ai_gateway = ai_gateway
        
        # åˆå§‹åŒ–æ£€æµ‹è§„åˆ™
        self.detection_rules = self._init_detection_rules()
        
        # å…³é”®ä¿¡æ¯æ£€æµ‹æ¨¡å¼
        self.key_info_patterns = self._init_key_info_patterns()
        
        # ä¿®å¤ç­–ç•¥
        self.fix_strategies = self._init_fix_strategies()
        
        logger.info(
            f"è´¨é‡æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ: strict={strict_mode}, "
            f"auto_fix={enable_auto_fix}, llm_fix={enable_llm_fix}"
        )
    
    def _init_detection_rules(self) -> List[Dict[str, Any]]:
        """åˆå§‹åŒ–æ£€æµ‹è§„åˆ™"""
        return [
            {
                'rule_id': 'missing_key_info',
                'name': 'ç¼ºå¤±å…³é”®ä¿¡æ¯',
                'severity': 'critical',
                'description': 'æ–‡æ¡£ç¼ºå°‘å¿…è¦çš„å…³é”®ä¿¡æ¯',
                'auto_fixable': True
            },
            {
                'rule_id': 'incomplete_content',
                'name': 'å†…å®¹ä¸å®Œæ•´',
                'severity': 'high',
                'description': 'æ–‡æ¡£å†…å®¹ä¸å®Œæ•´æˆ–è¢«æˆªæ–­',
                'auto_fixable': True
            },
            {
                'rule_id': 'poor_structure',
                'name': 'ç»“æ„æ··ä¹±',
                'severity': 'medium',
                'description': 'æ–‡æ¡£ç»“æ„ä¸æ¸…æ™°æˆ–ç¼ºå°‘å±‚æ¬¡',
                'auto_fixable': True
            },
            {
                'rule_id': 'duplicate_content',
                'name': 'é‡å¤å†…å®¹',
                'severity': 'high',
                'description': 'ä¸å·²æœ‰æ–‡æ¡£é‡å¤',
                'auto_fixable': False
            },
            {
                'rule_id': 'low_information_density',
                'name': 'ä¿¡æ¯å¯†åº¦ä½',
                'severity': 'medium',
                'description': 'æœ‰æ•ˆä¿¡æ¯å¤ªå°‘ï¼Œå……æ–¥å†—ä½™å†…å®¹',
                'auto_fixable': True
            },
            {
                'rule_id': 'inconsistent_format',
                'name': 'æ ¼å¼ä¸ä¸€è‡´',
                'severity': 'low',
                'description': 'æ–‡æ¡£æ ¼å¼ä¸ç¬¦åˆæ ‡å‡†',
                'auto_fixable': True
            }
        ]
    
    def _init_key_info_patterns(self) -> Dict[str, List[str]]:
        """åˆå§‹åŒ–å…³é”®ä¿¡æ¯æ£€æµ‹æ¨¡å¼"""
        return {
            'æŠ€æœ¯æ–‡æ¡£': [
                'åŠŸèƒ½æè¿°', 'ä½¿ç”¨æ–¹æ³•', 'å‚æ•°è¯´æ˜', 'ç¤ºä¾‹ä»£ç ', 'æ³¨æ„äº‹é¡¹'
            ],
            'äº§å“æ‰‹å†Œ': [
                'äº§å“åç§°', 'æŠ€æœ¯è§„æ ¼', 'å®‰è£…æ­¥éª¤', 'ä½¿ç”¨è¯´æ˜', 'ç»´æŠ¤ä¿å…»'
            ],
            'æ•…éšœæ’æŸ¥': [
                'é—®é¢˜æè¿°', 'æ•…éšœç°è±¡', 'åŸå› åˆ†æ', 'è§£å†³æ–¹æ¡ˆ', 'é¢„é˜²æªæ–½'
            ],
            'æ“ä½œæŒ‡å—': [
                'æ“ä½œæ­¥éª¤', 'å‰ç½®æ¡ä»¶', 'æ“ä½œè¯´æ˜', 'é¢„æœŸç»“æœ', 'å¼‚å¸¸å¤„ç†'
            ]
        }
    
    def _init_fix_strategies(self) -> Dict[str, Dict[str, Any]]:
        """åˆå§‹åŒ–ä¿®å¤ç­–ç•¥"""
        return {
            'missing_key_info': {
                'priority': 1,
                'method': 'llm_assisted',
                'prompt_template': 'æ–‡æ¡£ç¼ºå°‘{missing_fields}ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡è¡¥å……è¿™äº›ä¿¡æ¯'
            },
            'incomplete_content': {
                'priority': 2,
                'method': 'llm_assisted',
                'prompt_template': 'æ–‡æ¡£å†…å®¹ä¸å®Œæ•´ï¼Œè¯·è¡¥å……å®Œæ•´çš„å†…å®¹'
            },
            'poor_structure': {
                'priority': 3,
                'method': 'rule_based',
                'actions': ['add_headings', 'organize_sections', 'add_numbering']
            },
            'low_information_density': {
                'priority': 4,
                'method': 'llm_assisted',
                'prompt_template': 'æå–æ ¸å¿ƒä¿¡æ¯ï¼Œå»é™¤å†—ä½™å†…å®¹ï¼Œä¿æŒç®€æ´ä¸“ä¸š'
            },
            'inconsistent_format': {
                'priority': 5,
                'method': 'rule_based',
                'actions': ['standardize_format', 'fix_punctuation', 'normalize_spacing']
            }
        }
    
    async def inspect_document(
        self,
        document: Dict[str, Any],
        chunks: List[Dict[str, Any]],
        category: str = 'general'
    ) -> QualityFeedback:
        """
        æ·±åº¦æ£€æŸ¥æ–‡æ¡£è´¨é‡
        
        Args:
            document: æ–‡æ¡£å…ƒæ•°æ®
            chunks: æ–‡æ¡£åˆ†å—åˆ—è¡¨
            category: æ–‡æ¡£ç±»åˆ«
        
        Returns:
            è¯¦ç»†çš„è´¨é‡åé¦ˆæŠ¥å‘Š
        """
        logger.info(f"å¼€å§‹æ·±åº¦è´¨é‡æ£€æŸ¥: {document.get('title', 'unknown')}")
        
        issues = []
        warnings = []
        fix_suggestions = []
        
        # 1. æ£€æµ‹ç¼ºå¤±å…³é”®ä¿¡æ¯
        missing_info_issues = await self._detect_missing_key_info(chunks, category)
        issues.extend(missing_info_issues)
        
        # 2. æ£€æµ‹å†…å®¹å®Œæ•´æ€§
        completeness_issues = await self._detect_incomplete_content(chunks)
        issues.extend(completeness_issues)
        
        # 3. æ£€æµ‹ç»“æ„è´¨é‡
        structure_issues = await self._detect_structure_problems(chunks)
        issues.extend(structure_issues)
        
        # 4. æ£€æµ‹ä¿¡æ¯å¯†åº¦
        density_issues = await self._detect_low_density(chunks)
        issues.extend(density_issues)
        
        # 5. æ£€æµ‹æ ¼å¼ä¸€è‡´æ€§
        format_issues = await self._detect_format_inconsistency(chunks)
        issues.extend(format_issues)
        
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        overall_score = self._calculate_overall_score(issues, chunks)
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡
        passed = overall_score >= self.threshold and not any(
            issue.severity == 'critical' for issue in issues
        )
        
        # ç”Ÿæˆä¿®å¤å»ºè®®
        for issue in issues:
            if issue.auto_fixable:
                fix_suggestions.append(f"{issue.description} - å¯è‡ªåŠ¨ä¿®å¤")
            else:
                fix_suggestions.append(f"{issue.description} - éœ€äººå·¥å¤„ç†")
        
        # åˆ¤æ–­æ˜¯å¦æœ‰è‡ªåŠ¨ä¿®å¤å¯ç”¨
        auto_fix_available = any(issue.auto_fixable for issue in issues)
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥å®¡æ ¸
        manual_review_required = any(
            issue.severity in ['critical', 'high'] for issue in issues
        )
        
        # ç”Ÿæˆåé¦ˆæ¶ˆæ¯
        feedback_message = self._generate_feedback_message(
            overall_score, issues, passed
        )
        
        feedback = QualityFeedback(
            document_id=document.get('document_id', ''),
            overall_score=overall_score,
            passed=passed,
            issues=issues,
            warnings=warnings,
            fix_suggestions=fix_suggestions,
            auto_fix_available=auto_fix_available,
            manual_review_required=manual_review_required,
            feedback_message=feedback_message
        )
        
        logger.info(
            f"è´¨é‡æ£€æŸ¥å®Œæˆ: score={overall_score:.2f}, "
            f"issues={len(issues)}, passed={passed}"
        )
        
        return feedback
    
    async def auto_fix_issues(
        self,
        chunks: List[Dict[str, Any]],
        issues: List[QualityIssue]
    ) -> List[AutoFixResult]:
        """
        è‡ªåŠ¨ä¿®å¤è´¨é‡é—®é¢˜
        
        Args:
            chunks: æ–‡æ¡£åˆ†å—
            issues: è´¨é‡é—®é¢˜åˆ—è¡¨
        
        Returns:
            ä¿®å¤ç»“æœåˆ—è¡¨
        """
        if not self.enable_auto_fix:
            logger.warning("è‡ªåŠ¨ä¿®å¤æœªå¯ç”¨")
            return []
        
        fix_results = []
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºé—®é¢˜
        sorted_issues = sorted(
            [i for i in issues if i.auto_fixable],
            key=lambda x: self.fix_strategies.get(x.issue_type, {}).get('priority', 99)
        )
        
        for issue in sorted_issues:
            try:
                # è·å–ä¿®å¤ç­–ç•¥
                strategy = self.fix_strategies.get(issue.issue_type)
                if not strategy:
                    continue
                
                # æ ¹æ®ä¿®å¤æ–¹æ³•é€‰æ‹©ä¿®å¤å‡½æ•°
                if strategy['method'] == 'llm_assisted' and self.enable_llm_fix:
                    fix_result = await self._llm_assisted_fix(chunks, issue, strategy)
                elif strategy['method'] == 'rule_based':
                    fix_result = await self._rule_based_fix(chunks, issue, strategy)
                elif strategy['method'] == 'hybrid':
                    fix_result = await self._hybrid_fix(chunks, issue, strategy)
                else:
                    continue
                
                if fix_result:
                    fix_results.append(fix_result)
                
            except Exception as e:
                logger.error(f"ä¿®å¤é—®é¢˜å¤±è´¥ {issue.issue_id}: {e}")
        
        logger.info(f"è‡ªåŠ¨ä¿®å¤å®Œæˆ: {len(fix_results)} ä¸ªé—®é¢˜å·²ä¿®å¤")
        
        return fix_results
    
    async def _llm_assisted_fix(
        self,
        chunks: List[Dict[str, Any]],
        issue: QualityIssue,
        strategy: Dict[str, Any]
    ) -> Optional[AutoFixResult]:
        """å¤§æ¨¡å‹è¾…åŠ©ä¿®å¤"""
        if not self.ai_gateway:
            logger.warning("AIç½‘å…³æœªé…ç½®ï¼Œæ— æ³•ä½¿ç”¨å¤§æ¨¡å‹ä¿®å¤")
            return None
        
        # æ‰¾åˆ°å—å½±å“çš„chunk
        affected_chunk = None
        for chunk in chunks:
            if chunk.get('chunk_id') in issue.affected_chunks:
                affected_chunk = chunk
                break
        
        if not affected_chunk:
            return None
        
        original_content = affected_chunk.get('content', '')
        
        # æ„å»ºä¿®å¤æç¤ºè¯
        prompt_template = strategy.get('prompt_template', '')
        
        # æ ¹æ®é—®é¢˜ç±»å‹å®šåˆ¶æç¤ºè¯
        if issue.issue_type == 'missing_key_info':
            missing_fields = issue.description.split('ç¼ºå°‘')[1] if 'ç¼ºå°‘' in issue.description else 'å…³é”®ä¿¡æ¯'
            prompt = f"""è¯·åˆ†æå¹¶è¡¥å……ä»¥ä¸‹æ–‡æ¡£å†…å®¹ï¼š

åŸå§‹å†…å®¹ï¼š
{original_content}

é—®é¢˜ï¼šç¼ºå°‘{missing_fields}

è¦æ±‚ï¼š
1. æ ¹æ®ä¸Šä¸‹æ–‡æ¨æ–­å¹¶è¡¥å……ç¼ºå¤±çš„{missing_fields}
2. ä¿æŒåŸæœ‰å†…å®¹çš„å‡†ç¡®æ€§
3. è¡¥å……çš„å†…å®¹è¦ä¸“ä¸šã€å‡†ç¡®
4. ä¿æŒæ–‡æ¡£ç»“æ„æ¸…æ™°

è¯·è¾“å‡ºå®Œæ•´çš„ä¿®å¤åå†…å®¹ã€‚"""
        
        elif issue.issue_type == 'incomplete_content':
            prompt = f"""è¯·è¡¥å……å®Œæ•´ä»¥ä¸‹ä¸å®Œæ•´çš„æ–‡æ¡£å†…å®¹ï¼š

åŸå§‹å†…å®¹ï¼š
{original_content}

é—®é¢˜ï¼š{issue.description}

è¦æ±‚ï¼š
1. åˆ†æå†…å®¹ç¼ºå¤±çš„éƒ¨åˆ†
2. æ ¹æ®ä¸Šä¸‹æ–‡è¡¥å……å®Œæ•´
3. ä¿æŒé€»è¾‘è¿è´¯
4. ç¡®ä¿ä¿¡æ¯å‡†ç¡®

è¯·è¾“å‡ºå®Œæ•´çš„å†…å®¹ã€‚"""
        
        elif issue.issue_type == 'low_information_density':
            prompt = f"""è¯·ä¼˜åŒ–ä»¥ä¸‹å†…å®¹çš„ä¿¡æ¯å¯†åº¦ï¼š

åŸå§‹å†…å®¹ï¼š
{original_content}

é—®é¢˜ï¼š{issue.description}

è¦æ±‚ï¼š
1. æå–æ ¸å¿ƒä¿¡æ¯
2. å»é™¤å†—ä½™å’ŒåºŸè¯
3. ä¿æŒä¸“ä¸šæ€§
4. ç®€æ´æ˜äº†

è¯·è¾“å‡ºä¼˜åŒ–åçš„å†…å®¹ã€‚"""
        
        else:
            prompt = prompt_template.format(content=original_content)
        
        try:
            # è°ƒç”¨å¤§æ¨¡å‹
            response = await self.ai_gateway.generate(
                prompt=prompt,
                temperature=0.3,  # é™ä½æ¸©åº¦ï¼Œæ›´ä¿å®ˆ
                max_tokens=2000
            )
            
            fixed_content = response.get('content', '')
            
            if not fixed_content or fixed_content == original_content:
                return None
            
            # è¯„ä¼°ä¿®å¤è´¨é‡
            confidence = await self._evaluate_fix_quality(
                original_content, fixed_content, issue
            )
            
            # è®°å½•ä¿®æ”¹
            changes_made = [
                f"ä¿®å¤ç±»å‹: {issue.issue_type}",
                f"ä¿®å¤æ–¹æ³•: LLMè¾…åŠ©",
                f"ç½®ä¿¡åº¦: {confidence:.2f}"
            ]
            
            return AutoFixResult(
                success=True,
                original_content=original_content,
                fixed_content=fixed_content,
                fix_method='llm_assisted',
                confidence=confidence,
                changes_made=changes_made,
                requires_human_review=confidence < 0.8
            )
            
        except Exception as e:
            logger.error(f"å¤§æ¨¡å‹ä¿®å¤å¤±è´¥: {e}")
            return None
    
    async def _rule_based_fix(
        self,
        chunks: List[Dict[str, Any]],
        issue: QualityIssue,
        strategy: Dict[str, Any]
    ) -> Optional[AutoFixResult]:
        """åŸºäºè§„åˆ™çš„ä¿®å¤"""
        affected_chunk = None
        for chunk in chunks:
            if chunk.get('chunk_id') in issue.affected_chunks:
                affected_chunk = chunk
                break
        
        if not affected_chunk:
            return None
        
        original_content = affected_chunk.get('content', '')
        fixed_content = original_content
        changes_made = []
        
        # æ‰§è¡Œè§„åˆ™ä¿®å¤åŠ¨ä½œ
        actions = strategy.get('actions', [])
        
        for action in actions:
            if action == 'add_headings':
                fixed_content, changed = self._add_headings(fixed_content)
                if changed:
                    changes_made.append("æ·»åŠ æ ‡é¢˜")
            
            elif action == 'organize_sections':
                fixed_content, changed = self._organize_sections(fixed_content)
                if changed:
                    changes_made.append("ç»„ç»‡ç« èŠ‚")
            
            elif action == 'add_numbering':
                fixed_content, changed = self._add_numbering(fixed_content)
                if changed:
                    changes_made.append("æ·»åŠ ç¼–å·")
            
            elif action == 'standardize_format':
                fixed_content, changed = self._standardize_format(fixed_content)
                if changed:
                    changes_made.append("æ ‡å‡†åŒ–æ ¼å¼")
            
            elif action == 'fix_punctuation':
                fixed_content, changed = self._fix_punctuation(fixed_content)
                if changed:
                    changes_made.append("ä¿®å¤æ ‡ç‚¹")
            
            elif action == 'normalize_spacing':
                fixed_content, changed = self._normalize_spacing(fixed_content)
                if changed:
                    changes_made.append("è§„èŒƒåŒ–ç©ºæ ¼")
        
        if fixed_content == original_content:
            return None
        
        return AutoFixResult(
            success=True,
            original_content=original_content,
            fixed_content=fixed_content,
            fix_method='rule_based',
            confidence=0.95,  # è§„åˆ™ä¿®å¤ç½®ä¿¡åº¦è¾ƒé«˜
            changes_made=changes_made,
            requires_human_review=False
        )
    
    async def _hybrid_fix(
        self,
        chunks: List[Dict[str, Any]],
        issue: QualityIssue,
        strategy: Dict[str, Any]
    ) -> Optional[AutoFixResult]:
        """æ··åˆä¿®å¤ï¼ˆè§„åˆ™+å¤§æ¨¡å‹ï¼‰"""
        # å…ˆä½¿ç”¨è§„åˆ™ä¿®å¤
        rule_result = await self._rule_based_fix(chunks, issue, strategy)
        
        if not rule_result:
            return None
        
        # å¦‚æœè§„åˆ™ä¿®å¤æ•ˆæœä¸ç†æƒ³ï¼Œä½¿ç”¨å¤§æ¨¡å‹å¢å¼º
        if rule_result.confidence < 0.8 and self.enable_llm_fix:
            llm_result = await self._llm_assisted_fix(chunks, issue, strategy)
            if llm_result and llm_result.confidence > rule_result.confidence:
                llm_result.fix_method = 'hybrid'
                llm_result.changes_made.extend(rule_result.changes_made)
                return llm_result
        
        return rule_result
    
    async def _detect_missing_key_info(
        self,
        chunks: List[Dict[str, Any]],
        category: str
    ) -> List[QualityIssue]:
        """æ£€æµ‹ç¼ºå¤±çš„å…³é”®ä¿¡æ¯"""
        issues = []
        
        # è·å–è¯¥ç±»åˆ«åº”æœ‰çš„å…³é”®ä¿¡æ¯
        required_fields = self.key_info_patterns.get(category, [])
        if not required_fields:
            return issues
        
        # åˆå¹¶æ‰€æœ‰chunkå†…å®¹
        full_content = '\n'.join(chunk.get('content', '') for chunk in chunks)
        
        # æ£€æµ‹ç¼ºå¤±å­—æ®µ
        missing_fields = []
        for field in required_fields:
            # ç®€åŒ–æ£€æµ‹ï¼šæ£€æŸ¥å…³é”®è¯æ˜¯å¦å‡ºç°
            if field not in full_content and not any(
                keyword in full_content for keyword in field.split()
            ):
                missing_fields.append(field)
        
        if missing_fields:
            issue = QualityIssue(
                issue_id=f"missing_info_{category}",
                issue_type='missing_key_info',
                severity='critical' if len(missing_fields) > 2 else 'high',
                description=f"ç¼ºå°‘å…³é”®ä¿¡æ¯: {', '.join(missing_fields)}",
                affected_chunks=[chunk.get('chunk_id', '') for chunk in chunks],
                auto_fixable=True,
                fix_suggestion=f"å»ºè®®è¡¥å……: {', '.join(missing_fields)}"
            )
            issues.append(issue)
        
        return issues
    
    async def _detect_incomplete_content(
        self,
        chunks: List[Dict[str, Any]]
    ) -> List[QualityIssue]:
        """æ£€æµ‹ä¸å®Œæ•´å†…å®¹"""
        issues = []
        
        for chunk in chunks:
            content = chunk.get('content', '')
            
            # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
            is_truncated = (
                content.endswith('...') or
                content.endswith('ã€‚ã€‚ã€‚') or
                len(content) < 50 or
                not content.strip()
            )
            
            if is_truncated:
                issue = QualityIssue(
                    issue_id=f"incomplete_{chunk.get('chunk_id', '')}",
                    issue_type='incomplete_content',
                    severity='high',
                    description='å†…å®¹ä¸å®Œæ•´æˆ–è¢«æˆªæ–­',
                    affected_chunks=[chunk.get('chunk_id', '')],
                    auto_fixable=True,
                    fix_suggestion='å»ºè®®è¡¥å……å®Œæ•´å†…å®¹'
                )
                issues.append(issue)
        
        return issues
    
    async def _detect_structure_problems(
        self,
        chunks: List[Dict[str, Any]]
    ) -> List[QualityIssue]:
        """æ£€æµ‹ç»“æ„é—®é¢˜"""
        issues = []
        
        for chunk in chunks:
            content = chunk.get('content', '')
            
            # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘ç»“æ„
            has_structure = (
                '1.' in content or '2.' in content or  # ç¼–å·
                '#' in content or  # æ ‡é¢˜
                '\n\n' in content  # æ®µè½åˆ†éš”
            )
            
            if not has_structure and len(content) > 200:
                issue = QualityIssue(
                    issue_id=f"structure_{chunk.get('chunk_id', '')}",
                    issue_type='poor_structure',
                    severity='medium',
                    description='ç¼ºå°‘æ¸…æ™°çš„ç»“æ„å±‚æ¬¡',
                    affected_chunks=[chunk.get('chunk_id', '')],
                    auto_fixable=True,
                    fix_suggestion='å»ºè®®æ·»åŠ ç¼–å·æˆ–æ ‡é¢˜'
                )
                issues.append(issue)
        
        return issues
    
    async def _detect_low_density(
        self,
        chunks: List[Dict[str, Any]]
    ) -> List[QualityIssue]:
        """æ£€æµ‹ä½ä¿¡æ¯å¯†åº¦"""
        issues = []
        
        for chunk in chunks:
            content = chunk.get('content', '')
            words = content.split()
            
            if len(words) == 0:
                continue
            
            # ç®€å•æ£€æµ‹ï¼šè®¡ç®—æœ‰æ•ˆè¯æ±‡æ¯”ä¾‹
            filler_words = {'å—¯', 'å•Š', 'å‘ƒ', 'é‚£ä¸ª', 'è¿™ä¸ª', 'å°±æ˜¯', 'ç„¶å'}
            filler_count = sum(1 for word in words if word in filler_words)
            
            density = 1 - (filler_count / len(words))
            
            if density < 0.7:
                issue = QualityIssue(
                    issue_id=f"density_{chunk.get('chunk_id', '')}",
                    issue_type='low_information_density',
                    severity='medium',
                    description=f'ä¿¡æ¯å¯†åº¦ä½ï¼ˆ{density:.1%}ï¼‰ï¼Œå†—ä½™å†…å®¹è¿‡å¤š',
                    affected_chunks=[chunk.get('chunk_id', '')],
                    auto_fixable=True,
                    fix_suggestion='å»ºè®®å»é™¤å†—ä½™ï¼Œæå–æ ¸å¿ƒä¿¡æ¯'
                )
                issues.append(issue)
        
        return issues
    
    async def _detect_format_inconsistency(
        self,
        chunks: List[Dict[str, Any]]
    ) -> List[QualityIssue]:
        """æ£€æµ‹æ ¼å¼ä¸ä¸€è‡´"""
        issues = []
        
        # æ£€æŸ¥æ ‡ç‚¹ç¬¦å·ä¸€è‡´æ€§
        punctuation_styles = set()
        for chunk in chunks:
            content = chunk.get('content', '')
            if 'ã€‚' in content:
                punctuation_styles.add('chinese')
            if '.' in content and not 'ã€‚' in content:
                punctuation_styles.add('english')
        
        if len(punctuation_styles) > 1:
            issue = QualityIssue(
                issue_id='format_punctuation',
                issue_type='inconsistent_format',
                severity='low',
                description='æ ‡ç‚¹ç¬¦å·é£æ ¼ä¸ä¸€è‡´ï¼ˆä¸­è‹±æ–‡æ··ç”¨ï¼‰',
                affected_chunks=[chunk.get('chunk_id', '') for chunk in chunks],
                auto_fixable=True,
                fix_suggestion='å»ºè®®ç»Ÿä¸€ä½¿ç”¨ä¸­æ–‡æ ‡ç‚¹'
            )
            issues.append(issue)
        
        return issues
    
    def _calculate_overall_score(
        self,
        issues: List[QualityIssue],
        chunks: List[Dict[str, Any]]
    ) -> float:
        """è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°"""
        if not issues:
            return 1.0
        
        # åŸºç¡€åˆ†
        score = 1.0
        
        # æ ¹æ®é—®é¢˜ä¸¥é‡ç¨‹åº¦æ‰£åˆ†
        severity_weights = {
            'critical': 0.3,
            'high': 0.15,
            'medium': 0.08,
            'low': 0.03
        }
        
        for issue in issues:
            weight = severity_weights.get(issue.severity, 0.05)
            score -= weight
        
        return max(0.0, score)
    
    def _generate_feedback_message(
        self,
        score: float,
        issues: List[QualityIssue],
        passed: bool
    ) -> str:
        """ç”Ÿæˆåé¦ˆæ¶ˆæ¯"""
        if passed:
            return f"âœ… æ–‡æ¡£è´¨é‡åˆæ ¼ï¼ˆåˆ†æ•°: {score:.2f}ï¼‰ï¼Œå¯ä»¥å…¥åº“"
        
        message_parts = [
            f"âŒ æ–‡æ¡£è´¨é‡ä¸åˆæ ¼ï¼ˆåˆ†æ•°: {score:.2f}ï¼‰ï¼Œéœ€è¦æ”¹è¿›",
            f"\nå‘ç° {len(issues)} ä¸ªè´¨é‡é—®é¢˜ï¼š"
        ]
        
        for i, issue in enumerate(issues, 1):
            severity_emoji = {
                'critical': 'ğŸ”´',
                'high': 'ğŸŸ ',
                'medium': 'ğŸŸ¡',
                'low': 'âšª'
            }.get(issue.severity, 'âšª')
            
            message_parts.append(
                f"\n{i}. {severity_emoji} {issue.description}"
            )
            if issue.auto_fixable:
                message_parts.append(" [å¯è‡ªåŠ¨ä¿®å¤]")
        
        return ''.join(message_parts)
    
    async def _evaluate_fix_quality(
        self,
        original: str,
        fixed: str,
        issue: QualityIssue
    ) -> float:
        """è¯„ä¼°ä¿®å¤è´¨é‡"""
        # ç®€åŒ–è¯„ä¼°é€»è¾‘
        if not fixed or fixed == original:
            return 0.0
        
        # åŸºç¡€åˆ†
        confidence = 0.6
        
        # é•¿åº¦åˆç†æ€§
        if len(fixed) > len(original) * 0.8:
            confidence += 0.1
        
        # æ˜¯å¦åŒ…å«å…³é”®æ”¹è¿›
        if issue.issue_type == 'missing_key_info':
            # æ£€æŸ¥æ˜¯å¦è¡¥å……äº†å†…å®¹
            if len(fixed) > len(original):
                confidence += 0.2
        
        elif issue.issue_type == 'low_information_density':
            # æ£€æŸ¥æ˜¯å¦å‹ç¼©äº†å†…å®¹
            if len(fixed) < len(original):
                confidence += 0.2
        
        return min(confidence, 1.0)
    
    # è§„åˆ™ä¿®å¤è¾…åŠ©æ–¹æ³•
    
    def _add_headings(self, content: str) -> Tuple[str, bool]:
        """æ·»åŠ æ ‡é¢˜"""
        # ç®€åŒ–å®ç°
        return content, False
    
    def _organize_sections(self, content: str) -> Tuple[str, bool]:
        """ç»„ç»‡ç« èŠ‚"""
        # ç®€åŒ–å®ç°
        return content, False
    
    def _add_numbering(self, content: str) -> Tuple[str, bool]:
        """æ·»åŠ ç¼–å·"""
        # ç®€åŒ–å®ç°
        return content, False
    
    def _standardize_format(self, content: str) -> Tuple[str, bool]:
        """æ ‡å‡†åŒ–æ ¼å¼"""
        # ç®€åŒ–å®ç°
        return content, False
    
    def _fix_punctuation(self, content: str) -> Tuple[str, bool]:
        """ä¿®å¤æ ‡ç‚¹"""
        # ç®€åŒ–å®ç°
        return content, False
    
    def _normalize_spacing(self, content: str) -> Tuple[str, bool]:
        """è§„èŒƒåŒ–ç©ºæ ¼"""
        import re
        fixed = re.sub(r'\s+', ' ', content)
        return fixed, fixed != content
