#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ - SQLiteåˆ°Supabase
å°†ç°æœ‰çš„SQLiteæ•°æ®è¿ç§»åˆ°Supabaseæ•°æ®åº“
"""

import os
import sys
import sqlite3
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from modules.storage.unified_database import get_database_manager, init_database_manager

logger = logging.getLogger(__name__)


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""
    
    def __init__(self, sqlite_path: str = "data/data.db"):
        self.sqlite_path = sqlite_path
        self.db_manager = get_database_manager()
        
        logger.info(f"âœ… æ•°æ®è¿ç§»å™¨åˆå§‹åŒ–: {sqlite_path}")
    
    def check_sqlite_exists(self) -> bool:
        """æ£€æŸ¥SQLiteæ•°æ®åº“æ˜¯å¦å­˜åœ¨"""
        return Path(self.sqlite_path).exists()
    
    def get_sqlite_data(self) -> Dict[str, List[Dict[str, Any]]]:
        """ä»SQLiteè·å–æ‰€æœ‰æ•°æ®"""
        if not self.check_sqlite_exists():
            logger.warning(f"SQLiteæ•°æ®åº“ä¸å­˜åœ¨: {self.sqlite_path}")
            return {}
        
        conn = sqlite3.connect(self.sqlite_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        data = {}
        
        try:
            # è·å–ä¼šè¯æ•°æ®
            cursor.execute("SELECT * FROM sessions")
            sessions = [dict(row) for row in cursor.fetchall()]
            data['sessions'] = sessions
            logger.info(f"âœ… è·å–ä¼šè¯æ•°æ®: {len(sessions)}æ¡")
            
            # è·å–æ¶ˆæ¯æ•°æ®
            cursor.execute("SELECT * FROM messages")
            messages = [dict(row) for row in cursor.fetchall()]
            data['messages'] = messages
            logger.info(f"âœ… è·å–æ¶ˆæ¯æ•°æ®: {len(messages)}æ¡")
            
            # è·å–çŸ¥è¯†åº“æ•°æ®
            try:
                cursor.execute("SELECT * FROM knowledge_chunks")
                chunks = [dict(row) for row in cursor.fetchall()]
                data['knowledge_chunks'] = chunks
                logger.info(f"âœ… è·å–çŸ¥è¯†åº“æ•°æ®: {len(chunks)}æ¡")
            except sqlite3.OperationalError:
                logger.info("çŸ¥è¯†åº“è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                data['knowledge_chunks'] = []
            
            # è·å–é€Ÿç‡é™åˆ¶æ•°æ®
            try:
                cursor.execute("SELECT * FROM rate_limits")
                rate_limits = [dict(row) for row in cursor.fetchall()]
                data['rate_limits'] = rate_limits
                logger.info(f"âœ… è·å–é€Ÿç‡é™åˆ¶æ•°æ®: {len(rate_limits)}æ¡")
            except sqlite3.OperationalError:
                logger.info("é€Ÿç‡é™åˆ¶è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                data['rate_limits'] = []
            
            # è·å–ç³»ç»Ÿé…ç½®æ•°æ®
            try:
                cursor.execute("SELECT * FROM system_config")
                configs = [dict(row) for row in cursor.fetchall()]
                data['system_config'] = configs
                logger.info(f"âœ… è·å–ç³»ç»Ÿé…ç½®æ•°æ®: {len(configs)}æ¡")
            except sqlite3.OperationalError:
                logger.info("ç³»ç»Ÿé…ç½®è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                data['system_config'] = []
            
        except Exception as e:
            logger.error(f"âŒ è·å–SQLiteæ•°æ®å¤±è´¥: {e}")
            return {}
        finally:
            conn.close()
        
        return data
    
    def convert_datetime_fields(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è½¬æ¢datetimeå­—æ®µä¸ºISOæ ¼å¼å­—ç¬¦ä¸²"""
        converted = data.copy()
        
        datetime_fields = ['created_at', 'last_active_at', 'expires_at', 'received_at', 'responded_at', 'window_start', 'last_request_at', 'updated_at']
        
        for field in datetime_fields:
            if field in converted and converted[field]:
                try:
                    if isinstance(converted[field], str):
                        # å°è¯•è§£æä¸ºdatetimeå¯¹è±¡
                        dt = datetime.fromisoformat(converted[field].replace('Z', '+00:00'))
                        converted[field] = dt.isoformat()
                    elif isinstance(converted[field], datetime):
                        converted[field] = converted[field].isoformat()
                except (ValueError, TypeError) as e:
                    logger.warning(f"æ—¥æœŸå­—æ®µè½¬æ¢å¤±è´¥: {field}={converted[field]}, {e}")
                    converted[field] = None
        
        return converted
    
    async def migrate_sessions(self, sessions: List[Dict[str, Any]]) -> int:
        """è¿ç§»ä¼šè¯æ•°æ®"""
        migrated_count = 0
        
        for session in sessions:
            try:
                # è½¬æ¢datetimeå­—æ®µ
                session_data = self.convert_datetime_fields(session)
                
                # ç§»é™¤idå­—æ®µï¼ˆè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆï¼‰
                if 'id' in session_data:
                    del session_data['id']
                
                # åˆ›å»ºä¼šè¯
                result = await self.db_manager.create_session(session_data)
                if result:
                    migrated_count += 1
                    logger.debug(f"âœ… ä¼šè¯è¿ç§»æˆåŠŸ: {session_data.get('session_key')}")
                else:
                    logger.warning(f"âš ï¸ ä¼šè¯è¿ç§»å¤±è´¥: {session_data.get('session_key')}")
                    
            except Exception as e:
                logger.error(f"âŒ ä¼šè¯è¿ç§»å¤±è´¥: {session.get('session_key')}, {e}")
        
        logger.info(f"âœ… ä¼šè¯è¿ç§»å®Œæˆ: {migrated_count}/{len(sessions)}")
        return migrated_count
    
    async def migrate_messages(self, messages: List[Dict[str, Any]]) -> int:
        """è¿ç§»æ¶ˆæ¯æ•°æ®"""
        migrated_count = 0
        
        for message in messages:
            try:
                # è½¬æ¢datetimeå­—æ®µ
                message_data = self.convert_datetime_fields(message)
                
                # ç§»é™¤idå­—æ®µï¼ˆè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆï¼‰
                if 'id' in message_data:
                    del message_data['id']
                
                # åˆ›å»ºæ¶ˆæ¯
                result = await self.db_manager.create_message(message_data)
                if result:
                    migrated_count += 1
                    logger.debug(f"âœ… æ¶ˆæ¯è¿ç§»æˆåŠŸ: {message_data.get('request_id')}")
                else:
                    logger.warning(f"âš ï¸ æ¶ˆæ¯è¿ç§»å¤±è´¥: {message_data.get('request_id')}")
                    
            except Exception as e:
                logger.error(f"âŒ æ¶ˆæ¯è¿ç§»å¤±è´¥: {message.get('request_id')}, {e}")
        
        logger.info(f"âœ… æ¶ˆæ¯è¿ç§»å®Œæˆ: {migrated_count}/{len(messages)}")
        return migrated_count
    
    async def migrate_knowledge_chunks(self, chunks: List[Dict[str, Any]]) -> int:
        """è¿ç§»çŸ¥è¯†åº“æ•°æ®"""
        migrated_count = 0
        
        for chunk in chunks:
            try:
                # è½¬æ¢datetimeå­—æ®µ
                chunk_data = self.convert_datetime_fields(chunk)
                
                # ç§»é™¤idå­—æ®µï¼ˆè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆï¼‰
                if 'id' in chunk_data:
                    del chunk_data['id']
                
                # åˆ›å»ºçŸ¥è¯†åº“å—
                result = await self.db_manager.create_message(chunk_data)  # ä½¿ç”¨æ¶ˆæ¯è¡¨å­˜å‚¨
                if result:
                    migrated_count += 1
                    logger.debug(f"âœ… çŸ¥è¯†åº“å—è¿ç§»æˆåŠŸ: {chunk_data.get('chunk_id')}")
                else:
                    logger.warning(f"âš ï¸ çŸ¥è¯†åº“å—è¿ç§»å¤±è´¥: {chunk_data.get('chunk_id')}")
                    
            except Exception as e:
                logger.error(f"âŒ çŸ¥è¯†åº“å—è¿ç§»å¤±è´¥: {chunk.get('chunk_id')}, {e}")
        
        logger.info(f"âœ… çŸ¥è¯†åº“è¿ç§»å®Œæˆ: {migrated_count}/{len(chunks)}")
        return migrated_count
    
    async def migrate_rate_limits(self, rate_limits: List[Dict[str, Any]]) -> int:
        """è¿ç§»é€Ÿç‡é™åˆ¶æ•°æ®"""
        migrated_count = 0
        
        for rate_limit in rate_limits:
            try:
                # è½¬æ¢datetimeå­—æ®µ
                rate_limit_data = self.convert_datetime_fields(rate_limit)
                
                # ç§»é™¤idå­—æ®µï¼ˆè®©æ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆï¼‰
                if 'id' in rate_limit_data:
                    del rate_limit_data['id']
                
                # åˆ›å»ºé€Ÿç‡é™åˆ¶è®°å½•
                result = await self.db_manager.create_message(rate_limit_data)  # ä½¿ç”¨æ¶ˆæ¯è¡¨å­˜å‚¨
                if result:
                    migrated_count += 1
                    logger.debug(f"âœ… é€Ÿç‡é™åˆ¶è¿ç§»æˆåŠŸ: {rate_limit_data.get('entity_type')}:{rate_limit_data.get('entity_id')}")
                else:
                    logger.warning(f"âš ï¸ é€Ÿç‡é™åˆ¶è¿ç§»å¤±è´¥: {rate_limit_data.get('entity_type')}:{rate_limit_data.get('entity_id')}")
                    
            except Exception as e:
                logger.error(f"âŒ é€Ÿç‡é™åˆ¶è¿ç§»å¤±è´¥: {rate_limit.get('entity_type')}:{rate_limit.get('entity_id')}, {e}")
        
        logger.info(f"âœ… é€Ÿç‡é™åˆ¶è¿ç§»å®Œæˆ: {migrated_count}/{len(rate_limits)}")
        return migrated_count
    
    async def migrate_system_config(self, configs: List[Dict[str, Any]]) -> int:
        """è¿ç§»ç³»ç»Ÿé…ç½®æ•°æ®"""
        migrated_count = 0
        
        for config in configs:
            try:
                # è®¾ç½®ç¯å¢ƒå˜é‡
                key = config.get('key')
                value = config.get('value')
                
                if key and value:
                    os.environ[key] = value
                    migrated_count += 1
                    logger.debug(f"âœ… ç³»ç»Ÿé…ç½®è¿ç§»æˆåŠŸ: {key}={value}")
                else:
                    logger.warning(f"âš ï¸ ç³»ç»Ÿé…ç½®è¿ç§»å¤±è´¥: {config}")
                    
            except Exception as e:
                logger.error(f"âŒ ç³»ç»Ÿé…ç½®è¿ç§»å¤±è´¥: {config}, {e}")
        
        logger.info(f"âœ… ç³»ç»Ÿé…ç½®è¿ç§»å®Œæˆ: {migrated_count}/{len(configs)}")
        return migrated_count
    
    async def migrate_all(self) -> Dict[str, int]:
        """è¿ç§»æ‰€æœ‰æ•°æ®"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®è¿ç§»...")
        
        # è·å–SQLiteæ•°æ®
        sqlite_data = self.get_sqlite_data()
        if not sqlite_data:
            logger.error("âŒ æ²¡æœ‰æ•°æ®å¯è¿ç§»")
            return {}
        
        # è¿ç§»ç»“æœç»Ÿè®¡
        results = {}
        
        # è¿ç§»ä¼šè¯
        if 'sessions' in sqlite_data and sqlite_data['sessions']:
            results['sessions'] = await self.migrate_sessions(sqlite_data['sessions'])
        
        # è¿ç§»æ¶ˆæ¯
        if 'messages' in sqlite_data and sqlite_data['messages']:
            results['messages'] = await self.migrate_messages(sqlite_data['messages'])
        
        # è¿ç§»çŸ¥è¯†åº“
        if 'knowledge_chunks' in sqlite_data and sqlite_data['knowledge_chunks']:
            results['knowledge_chunks'] = await self.migrate_knowledge_chunks(sqlite_data['knowledge_chunks'])
        
        # è¿ç§»é€Ÿç‡é™åˆ¶
        if 'rate_limits' in sqlite_data and sqlite_data['rate_limits']:
            results['rate_limits'] = await self.migrate_rate_limits(sqlite_data['rate_limits'])
        
        # è¿ç§»ç³»ç»Ÿé…ç½®
        if 'system_config' in sqlite_data and sqlite_data['system_config']:
            results['system_config'] = await self.migrate_system_config(sqlite_data['system_config'])
        
        logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆ!")
        return results
    
    def backup_sqlite(self, backup_path: str = None) -> str:
        """å¤‡ä»½SQLiteæ•°æ®åº“"""
        if not self.check_sqlite_exists():
            logger.warning("SQLiteæ•°æ®åº“ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½")
            return ""
        
        if not backup_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"data/data_backup_{timestamp}.db"
        
        import shutil
        shutil.copy2(self.sqlite_path, backup_path)
        logger.info(f"âœ… SQLiteæ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
        return backup_path
    
    def verify_migration(self) -> Dict[str, Any]:
        """éªŒè¯è¿ç§»ç»“æœ"""
        logger.info("ğŸ” éªŒè¯è¿ç§»ç»“æœ...")
        
        # è·å–SQLiteæ•°æ®ç»Ÿè®¡
        sqlite_data = self.get_sqlite_data()
        sqlite_stats = {
            'sessions': len(sqlite_data.get('sessions', [])),
            'messages': len(sqlite_data.get('messages', [])),
            'knowledge_chunks': len(sqlite_data.get('knowledge_chunks', [])),
            'rate_limits': len(sqlite_data.get('rate_limits', [])),
            'system_config': len(sqlite_data.get('system_config', []))
        }
        
        # è·å–Supabaseæ•°æ®ç»Ÿè®¡
        import asyncio
        supabase_stats = asyncio.run(self.db_manager.get_stats())
        
        verification_result = {
            'sqlite_stats': sqlite_stats,
            'supabase_stats': supabase_stats,
            'migration_success': True,
            'verification_time': datetime.now().isoformat()
        }
        
        # æ£€æŸ¥å…³é”®æ•°æ®æ˜¯å¦è¿ç§»æˆåŠŸ
        if sqlite_stats['sessions'] > 0 and supabase_stats.get('session_count', 0) == 0:
            verification_result['migration_success'] = False
            verification_result['error'] = "ä¼šè¯æ•°æ®è¿ç§»å¤±è´¥"
        
        if sqlite_stats['messages'] > 0 and supabase_stats.get('message_count', 0) == 0:
            verification_result['migration_success'] = False
            verification_result['error'] = "æ¶ˆæ¯æ•°æ®è¿ç§»å¤±è´¥"
        
        logger.info(f"âœ… éªŒè¯å®Œæˆ: {verification_result}")
        return verification_result


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ SQLiteåˆ°Supabaseæ•°æ®è¿ç§»å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("SUPABASE_URL") or not os.getenv("SUPABASE_ANON_KEY"):
        print("âŒ Supabaseé…ç½®ä¸å®Œæ•´")
        print("è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡:")
        print("  SUPABASE_URL=https://your-project.supabase.co")
        print("  SUPABASE_ANON_KEY=your_supabase_anon_key")
        return False
    
    # åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
    init_database_manager()
    
    # åˆ›å»ºè¿ç§»å™¨
    migrator = DataMigrator()
    
    # æ£€æŸ¥SQLiteæ•°æ®åº“
    if not migrator.check_sqlite_exists():
        print("âŒ SQLiteæ•°æ®åº“ä¸å­˜åœ¨")
        print(f"è¯·æ£€æŸ¥è·¯å¾„: {migrator.sqlite_path}")
        return False
    
    print(f"âœ… æ‰¾åˆ°SQLiteæ•°æ®åº“: {migrator.sqlite_path}")
    
    # å¤‡ä»½SQLiteæ•°æ®åº“
    backup_path = migrator.backup_sqlite()
    if backup_path:
        print(f"âœ… å·²å¤‡ä»½SQLiteæ•°æ®åº“: {backup_path}")
    
    # å¼€å§‹è¿ç§»
    print("ğŸ”„ å¼€å§‹æ•°æ®è¿ç§»...")
    results = await migrator.migrate_all()
    
    # æ˜¾ç¤ºè¿ç§»ç»“æœ
    print("\nğŸ“Š è¿ç§»ç»“æœ:")
    for table, count in results.items():
        print(f"  {table}: {count}æ¡")
    
    # éªŒè¯è¿ç§»
    print("\nğŸ” éªŒè¯è¿ç§»ç»“æœ...")
    verification = migrator.verify_migration()
    
    if verification['migration_success']:
        print("âœ… æ•°æ®è¿ç§»æˆåŠŸ!")
        print(f"  SQLiteç»Ÿè®¡: {verification['sqlite_stats']}")
        print(f"  Supabaseç»Ÿè®¡: {verification['supabase_stats']}")
    else:
        print("âŒ æ•°æ®è¿ç§»å¤±è´¥!")
        print(f"  é”™è¯¯: {verification.get('error', 'æœªçŸ¥é”™è¯¯')}")
        return False
    
    return True


if __name__ == "__main__":
    import asyncio
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s [%(levelname)s] %(name)s: %(message)s'
    )
    
    # è¿è¡Œè¿ç§»
    success = asyncio.run(main())
    
    if success:
        print("\nğŸ‰ æ•°æ®è¿ç§»å®Œæˆ!")
        print("ç°åœ¨å¯ä»¥è®¾ç½® DATABASE_TYPE=supabase ä½¿ç”¨Supabaseæ•°æ®åº“")
    else:
        print("\nâŒ æ•°æ®è¿ç§»å¤±è´¥!")
        sys.exit(1)
