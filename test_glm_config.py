#!/usr/bin/env python3
"""
æµ‹è¯•æ™ºè°± GLM API é…ç½®
"""
import os
import requests
import json

# GLM é…ç½®
API_KEY = os.getenv("GLM_API_KEY", "your-glm-api-key-here")
BASE_URL = "https://open.bigmodel.cn/api/coding/paas/v4"

def test_glm_connection():
    """æµ‹è¯• GLM API è¿æ¥"""
    
    print("=" * 60)
    print("ğŸ§ª æµ‹è¯•æ™ºè°± GLM API é…ç½®")
    print("=" * 60)
    
    # æµ‹è¯• 1: æ£€æŸ¥æ¥å£åœ°å€
    print(f"\nğŸ“ æ¥å£åœ°å€: {BASE_URL}")
    
    # æµ‹è¯• 2: å°è¯•è°ƒç”¨ chat completions
    url = f"{BASE_URL}/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "model": "glm-4-flash",  # ä½¿ç”¨æœ€å¿«çš„æ¨¡å‹æµ‹è¯•
        "messages": [
            {
                "role": "user",
                "content": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªè¿æ¥æµ‹è¯•"
            }
        ],
        "max_tokens": 10
    }
    
    print(f"\nğŸ”‘ API Key: {API_KEY[:20]}...{API_KEY[-10:]}")
    print(f"ğŸ“¦ æµ‹è¯•æ¨¡å‹: glm-4-flash")
    print(f"\nâ³ æ­£åœ¨å‘é€è¯·æ±‚...")
    
    try:
        response = requests.post(
            url,
            headers=headers,
            json=payload,
            timeout=10
        )
        
        print(f"\nğŸ“Š å“åº”çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            print("âœ… è¿æ¥æˆåŠŸï¼")
            result = response.json()
            print(f"\nğŸ“ API å“åº”:")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0].get('message', {}).get('content', '')
                print(f"\nğŸ’¬ æ¨¡å‹å›å¤: {content}")
            
            return True
        else:
            print(f"âŒ è¿æ¥å¤±è´¥ï¼")
            print(f"\né”™è¯¯è¯¦æƒ…:")
            print(response.text)
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ï¼è¯·æ£€æŸ¥æ¥å£åœ°å€")
        return False
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        return False

def test_available_models():
    """æµ‹è¯•å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ™ºè°± GLM å¸¸ç”¨æ¨¡å‹")
    print("=" * 60)
    
    models = [
        ("glm-4-flash", "æœ€å¿«ï¼Œé€‚åˆç®€å•å¯¹è¯", "å…è´¹"),
        ("glm-4", "æ ‡å‡†æ¨¡å‹ï¼Œæ€§èƒ½å‡è¡¡", "0.1å…ƒ/åƒtokens"),
        ("glm-4-plus", "å¢å¼ºç‰ˆï¼Œæ›´å¼ºæ¨ç†", "0.5å…ƒ/åƒtokens"),
        ("glm-4-air", "è½»é‡çº§ï¼Œé€Ÿåº¦å¿«", "0.001å…ƒ/åƒtokens"),
    ]
    
    for model_name, desc, price in models:
        print(f"\nâ€¢ {model_name:20} - {desc:30} [{price}]")

if __name__ == "__main__":
    # æµ‹è¯•è¿æ¥
    success = test_glm_connection()
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    test_available_models()
    
    print("\n" + "=" * 60)
    if success:
        print("âœ… GLM é…ç½®æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
    else:
        print("âŒ GLM é…ç½®æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š")
        print("   1. API Key æ˜¯å¦æ­£ç¡®")
        print("   2. æ¥å£åœ°å€æ˜¯å¦æ­£ç¡®")
        print("   3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        print("   4. è´¦æˆ·ä½™é¢æ˜¯å¦å……è¶³")
    print("=" * 60)

